{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1023e927",
   "metadata": {},
   "source": [
    "# Improvements: Top-N groups + hard-negative mining (Cross-Encoder)\n",
    "\n",
    "This notebook upgrades the **hierarchical + description-aware cross-encoder** solution by adding:\n",
    "\n",
    "1) **Top-N groups** shortlist (e.g., N=3) instead of top-1 group  \n",
    "2) **Hard-negative mining** from model confusions (within-group) and optional cross-group (from top-N)\n",
    "\n",
    "You get:\n",
    "- Baseline evaluation (top-1 group, random negatives)\n",
    "- Improved evaluation (top-N groups)\n",
    "- Fine-tuned cross-encoder with mined hard negatives\n",
    "- Final comparison table\n",
    "\n",
    "## Inputs\n",
    "- `dataset.csv`: columns `text`, `demand_id`, `relevant`/`relevance`, `group_id`\n",
    "- `labels.csv`: columns `demand_id`, `description` (and optionally `group_id`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705edda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CONFIG (EDIT THESE)\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_CSV = Path(\"dataset.csv\")\n",
    "LABELS_CSV  = Path(\"labels.csv\")\n",
    "\n",
    "TEXT_COL   = \"text\"\n",
    "DEMAND_COL = \"demand_id\"\n",
    "GROUP_COL  = \"group_id\"\n",
    "REL_COL_CANDIDATES = [\"relevant\", \"relevance\"]\n",
    "\n",
    "SEED = 42\n",
    "TEST_SIZE = 0.30\n",
    "\n",
    "# Stage A: Group classifier\n",
    "TFIDF_NGRAM = (1,3)\n",
    "TOP_N_GROUPS = 3          # <-- improvement: evaluate with top-3 groups\n",
    "TOP_K_LABELS = 5          # report top-5\n",
    "\n",
    "# Cross-Encoder backbone (English)\n",
    "CE_MODEL = \"microsoft/deberta-v3-base\"\n",
    "CE_MAX_LEN = 256\n",
    "CE_EPOCHS_BASE = 2\n",
    "CE_EPOCHS_HARD = 1        # extra fine-tune epochs on hard negatives\n",
    "CE_BS = 8\n",
    "CE_LR = 2e-5\n",
    "\n",
    "# Pairing\n",
    "NEG_PER_POS_RANDOM = 3    # baseline random negatives within group\n",
    "HARD_NEG_PER_POS = 2      # mined hard negatives per positive\n",
    "\n",
    "# Mining settings\n",
    "MINE_FROM = \"val\"         # \"val\" or \"train_sample\"\n",
    "MAX_CANDIDATES_PER_GROUP_FOR_MINING = 128  # speed cap: sample candidate labels per group when mining (None for all)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "RNG = np.random.default_rng(SEED)\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe124ce",
   "metadata": {},
   "source": [
    "## 1) Load + merge + keep relevant==1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8e97c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_CSV)\n",
    "labels = pd.read_csv(LABELS_CSV)\n",
    "\n",
    "# detect relevance column\n",
    "rel_col = None\n",
    "for c in REL_COL_CANDIDATES:\n",
    "    if c in df.columns:\n",
    "        rel_col = c\n",
    "        break\n",
    "if rel_col is None:\n",
    "    raise ValueError(f\"Missing relevance column. Tried: {REL_COL_CANDIDATES}. Have: {list(df.columns)}\")\n",
    "\n",
    "for c in [TEXT_COL, DEMAND_COL]:\n",
    "    if c not in df.columns:\n",
    "        raise ValueError(f\"Dataset missing column: {c}\")\n",
    "for c in [DEMAND_COL, \"description\"]:\n",
    "    if c not in labels.columns:\n",
    "        raise ValueError(f\"Labels file missing column: {c}\")\n",
    "\n",
    "df[rel_col] = df[rel_col].fillna(0).astype(int)\n",
    "df[DEMAND_COL] = df[DEMAND_COL].astype(str)\n",
    "labels[DEMAND_COL] = labels[DEMAND_COL].astype(str)\n",
    "\n",
    "# bring group_id if missing\n",
    "if GROUP_COL not in df.columns and GROUP_COL in labels.columns:\n",
    "    df = df.merge(labels[[DEMAND_COL, GROUP_COL]], on=DEMAND_COL, how=\"left\")\n",
    "if GROUP_COL not in df.columns:\n",
    "    raise ValueError(f\"Missing {GROUP_COL}. Provide in dataset.csv or labels.csv and set GROUP_COL.\")\n",
    "\n",
    "# merge descriptions into df\n",
    "df = df.merge(labels[[DEMAND_COL, \"description\"]], on=DEMAND_COL, how=\"left\")\n",
    "\n",
    "df_rel = df[df[rel_col] == 1].dropna(subset=[TEXT_COL, DEMAND_COL, GROUP_COL, \"description\"]).copy()\n",
    "df_rel[GROUP_COL] = df_rel[GROUP_COL].astype(str)\n",
    "\n",
    "print(\"Relevant rows:\", len(df_rel))\n",
    "print(\"Unique labels:\", df_rel[DEMAND_COL].nunique(), \"Unique groups:\", df_rel[GROUP_COL].nunique())\n",
    "df_rel.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b998c966",
   "metadata": {},
   "source": [
    "## 2) Shared train/val split (stratify by group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308df6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(\n",
    "    df_rel,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=SEED,\n",
    "    stratify=df_rel[GROUP_COL] if df_rel[GROUP_COL].nunique() > 1 else None,\n",
    ")\n",
    "\n",
    "print(\"Train:\", train_df.shape, \"Val:\", val_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b2c5e",
   "metadata": {},
   "source": [
    "## 3) Stage A — Group classifier (shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5819f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "group_pipe = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(min_df=2, max_df=0.95, ngram_range=TFIDF_NGRAM)),\n",
    "    (\"clf\", LinearSVC(class_weight=\"balanced\", max_iter=8000)),\n",
    "])\n",
    "group_pipe.fit(train_df[TEXT_COL].astype(str), train_df[GROUP_COL])\n",
    "\n",
    "group_cal = CalibratedClassifierCV(group_pipe, method=\"sigmoid\", cv=3)\n",
    "group_cal.fit(train_df[TEXT_COL].astype(str), train_df[GROUP_COL])\n",
    "\n",
    "pred_groups = group_cal.predict(val_df[TEXT_COL].astype(str))\n",
    "print(classification_report(val_df[GROUP_COL], pred_groups, zero_division=0))\n",
    "print(\"Stage A trained in %.1fs\" % (time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845065b7",
   "metadata": {},
   "source": [
    "## 4) Build group -> candidate labels (demand_id, description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_rel = labels.merge(df_rel[[DEMAND_COL, GROUP_COL]].drop_duplicates(), on=DEMAND_COL, how=\"inner\")\n",
    "labels_rel = labels_rel.dropna(subset=[GROUP_COL, \"description\"]).copy()\n",
    "labels_rel[GROUP_COL] = labels_rel[GROUP_COL].astype(str)\n",
    "\n",
    "group_to_labels = {}\n",
    "for g, sub in labels_rel.groupby(GROUP_COL):\n",
    "    # dedupe\n",
    "    sub = sub.drop_duplicates(subset=[DEMAND_COL], keep=\"first\")\n",
    "    group_to_labels[str(g)] = list(zip(sub[DEMAND_COL].astype(str).tolist(), sub[\"description\"].astype(str).tolist()))\n",
    "\n",
    "print(\"Groups with candidates:\", len(group_to_labels))\n",
    "print(\"Example group sizes:\", sorted([(g, len(v)) for g, v in group_to_labels.items()], key=lambda x: -x[1])[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e944a211",
   "metadata": {},
   "source": [
    "## 5) Cross-Encoder baseline training (random negatives within group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fc0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_pairs(df_part: pd.DataFrame, neg_per_pos: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df_part.iterrows():\n",
    "        text = str(r[TEXT_COL])\n",
    "        demand = str(r[DEMAND_COL])\n",
    "        group = str(r[GROUP_COL])\n",
    "        desc_pos = str(r[\"description\"])\n",
    "\n",
    "        rows.append({\"text\": text, \"description\": desc_pos, \"labels\": 1, \"group\": group, \"true_demand\": demand})\n",
    "\n",
    "        candidates = group_to_labels.get(group, [])\n",
    "        neg_pool = [(d, desc) for d, desc in candidates if d != demand]\n",
    "        if not neg_pool:\n",
    "            continue\n",
    "        take = min(neg_per_pos, len(neg_pool))\n",
    "        neg_idx = RNG.choice(len(neg_pool), size=take, replace=False)\n",
    "        for i in np.atleast_1d(neg_idx):\n",
    "            _, desc_neg = neg_pool[int(i)]\n",
    "            rows.append({\"text\": text, \"description\": str(desc_neg), \"labels\": 0, \"group\": group, \"true_demand\": demand})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "ce_train_pairs = make_random_pairs(train_df, NEG_PER_POS_RANDOM)\n",
    "ce_val_pairs = make_random_pairs(val_df, NEG_PER_POS_RANDOM)\n",
    "\n",
    "print(\"Train pairs:\", ce_train_pairs.shape, \"pos rate:\", ce_train_pairs['labels'].mean())\n",
    "print(\"Val pairs  :\", ce_val_pairs.shape, \"pos rate:\", ce_val_pairs['labels'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620a328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_tokenizer = AutoTokenizer.from_pretrained(CE_MODEL)\n",
    "\n",
    "def ce_tok(batch):\n",
    "    return ce_tokenizer(\n",
    "        batch[\"text\"], batch[\"description\"],\n",
    "        truncation=True, padding=\"max_length\", max_length=CE_MAX_LEN\n",
    "    )\n",
    "\n",
    "def to_hf_ds(pairs_df: pd.DataFrame) -> Dataset:\n",
    "    ds = Dataset.from_pandas(pairs_df[[\"text\",\"description\",\"labels\"]], preserve_index=False)\n",
    "    ds = ds.map(ce_tok, batched=True)\n",
    "    ds.set_format(type=\"torch\", columns=[\"input_ids\",\"attention_mask\",\"labels\"])\n",
    "    return ds\n",
    "\n",
    "ce_train_ds = to_hf_ds(ce_train_pairs)\n",
    "ce_val_ds = to_hf_ds(ce_val_pairs)\n",
    "\n",
    "ce_model = AutoModelForSequenceClassification.from_pretrained(CE_MODEL, num_labels=2).to(device)\n",
    "\n",
    "ce_args = TrainingArguments(\n",
    "    output_dir=\"ce_improve_out\",\n",
    "    learning_rate=CE_LR,\n",
    "    per_device_train_batch_size=CE_BS,\n",
    "    per_device_eval_batch_size=CE_BS,\n",
    "    num_train_epochs=CE_EPOCHS_BASE,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "ce_trainer = Trainer(model=ce_model, args=ce_args, train_dataset=ce_train_ds, eval_dataset=ce_val_ds)\n",
    "t0 = time.time()\n",
    "ce_trainer.train()\n",
    "print(\"Baseline CE trained in %.1fs\" % (time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954c4b72",
   "metadata": {},
   "source": [
    "## 6) Evaluation helper: Top-N groups → score union of candidate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def ce_score_probs(text: str, descriptions: list[str]) -> np.ndarray:\n",
    "    batch = ce_tokenizer([text]*len(descriptions), descriptions, padding=True, truncation=True, max_length=CE_MAX_LEN, return_tensors=\"pt\")\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    logits = ce_model(**batch).logits\n",
    "    probs = F.softmax(logits, dim=-1)[:, 1].detach().cpu().numpy()\n",
    "    return probs\n",
    "\n",
    "def top_n_groups_for_text(texts: pd.Series, n: int) -> np.ndarray:\n",
    "    probs = group_cal.predict_proba(texts.astype(str))\n",
    "    classes = group_cal.classes_\n",
    "    topn = np.argsort(-probs, axis=1)[:, :n]\n",
    "    return classes[topn]\n",
    "\n",
    "def predict_topk_union(text: str, groups: list[str], k: int) -> list[str]:\n",
    "    # union candidates from groups\n",
    "    cand = []\n",
    "    for g in groups:\n",
    "        cand.extend(group_to_labels.get(str(g), []))\n",
    "    if not cand:\n",
    "        return []\n",
    "    # dedupe demand_id (keep first)\n",
    "    seen=set(); demand_ids=[]; descs=[]\n",
    "    for did, desc in cand:\n",
    "        if did in seen: \n",
    "            continue\n",
    "        seen.add(did)\n",
    "        demand_ids.append(did)\n",
    "        descs.append(desc)\n",
    "\n",
    "    scores = ce_score_probs(text, descs)\n",
    "    order = np.argsort(-scores)[:k]\n",
    "    return [demand_ids[i] for i in order]\n",
    "\n",
    "def evaluate_topk(df_part: pd.DataFrame, top_n_groups: int, top_k_labels: int):\n",
    "    groups_topn = top_n_groups_for_text(df_part[TEXT_COL], top_n_groups)\n",
    "    y_true = df_part[DEMAND_COL].astype(str).tolist()\n",
    "    texts = df_part[TEXT_COL].astype(str).tolist()\n",
    "\n",
    "    top1=0; topk=0; valid=0\n",
    "    for text, true_lab, g_row in zip(texts, y_true, groups_topn):\n",
    "        preds = predict_topk_union(text, list(g_row), top_k_labels)\n",
    "        if not preds:\n",
    "            continue\n",
    "        valid += 1\n",
    "        top1 += int(preds[0] == true_lab)\n",
    "        topk += int(true_lab in preds)\n",
    "    return {\n",
    "        \"eval_rows\": valid,\n",
    "        \"top1\": top1 / max(1,valid),\n",
    "        f\"top{top_k_labels}\": topk / max(1,valid),\n",
    "    }\n",
    "\n",
    "baseline_top1group = evaluate_topk(val_df, top_n_groups=1, top_k_labels=TOP_K_LABELS)\n",
    "baseline_topNgroups = evaluate_topk(val_df, top_n_groups=TOP_N_GROUPS, top_k_labels=TOP_K_LABELS)\n",
    "\n",
    "print(\"Baseline CE + top-1 group:\", baseline_top1group)\n",
    "print(f\"Baseline CE + top-{TOP_N_GROUPS} groups:\", baseline_topNgroups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d67df59",
   "metadata": {},
   "source": [
    "## 7) Hard-negative mining (within-group), then extra fine-tune\n",
    "\n",
    "Mining strategy (simple and effective):\n",
    "For each (text, true_label) in the mining set:\n",
    "- score all candidate labels in its **true group** (or sampled subset for speed)\n",
    "- take the highest-scoring **incorrect** labels as **hard negatives**\n",
    "- add those pairs to training data and fine-tune 1 more epoch\n",
    "\n",
    "This targets your pain: *ultra-similar labels within the same group*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c1462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mine_hard_negatives(df_part: pd.DataFrame, hard_neg_per_pos: int) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, r in df_part.iterrows():\n",
    "        text = str(r[TEXT_COL])\n",
    "        true_demand = str(r[DEMAND_COL])\n",
    "        group = str(r[GROUP_COL])\n",
    "        cand = group_to_labels.get(group, [])\n",
    "        if not cand:\n",
    "            continue\n",
    "\n",
    "        # optional sampling for speed on big groups\n",
    "        if MAX_CANDIDATES_PER_GROUP_FOR_MINING and len(cand) > MAX_CANDIDATES_PER_GROUP_FOR_MINING:\n",
    "            idx = RNG.choice(len(cand), size=MAX_CANDIDATES_PER_GROUP_FOR_MINING, replace=False)\n",
    "            cand = [cand[int(i)] for i in idx]\n",
    "\n",
    "        demand_ids = [d for d, _ in cand]\n",
    "        descs = [desc for _, desc in cand]\n",
    "\n",
    "        scores = ce_score_probs(text, descs)\n",
    "        order = np.argsort(-scores)\n",
    "\n",
    "        # select top incorrect labels\n",
    "        hard = []\n",
    "        for i in order:\n",
    "            did = demand_ids[int(i)]\n",
    "            if did == true_demand:\n",
    "                continue\n",
    "            hard.append((did, descs[int(i)]))\n",
    "            if len(hard) >= hard_neg_per_pos:\n",
    "                break\n",
    "\n",
    "        # build pairs: positives + hard negatives\n",
    "        # positive (ensure we have correct description from df)\n",
    "        rows.append({\"text\": text, \"description\": str(r[\"description\"]), \"labels\": 1})\n",
    "        for _, desc_neg in hard:\n",
    "            rows.append({\"text\": text, \"description\": str(desc_neg), \"labels\": 0})\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "mine_src = val_df if MINE_FROM == \"val\" else train_df.sample(min(len(train_df), 2000), random_state=SEED)\n",
    "\n",
    "hard_pairs = mine_hard_negatives(mine_src, HARD_NEG_PER_POS)\n",
    "print(\"Hard mined pairs:\", hard_pairs.shape, \"pos rate:\", hard_pairs[\"labels\"].mean())\n",
    "hard_pairs.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41b96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune on union(train_pairs + hard_pairs)\n",
    "# (Keep it small: 1 epoch is typically enough)\n",
    "\n",
    "ft_pairs = pd.concat([ce_train_pairs[[\"text\",\"description\",\"labels\"]], hard_pairs], ignore_index=True)\n",
    "\n",
    "ft_train_ds = to_hf_ds(ft_pairs)\n",
    "\n",
    "# reuse same model/tokenizer, continue training\n",
    "ce_args_hard = TrainingArguments(\n",
    "    output_dir=\"ce_improve_out_hard\",\n",
    "    learning_rate=CE_LR,\n",
    "    per_device_train_batch_size=CE_BS,\n",
    "    per_device_eval_batch_size=CE_BS,\n",
    "    num_train_epochs=CE_EPOCHS_HARD,\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"no\",\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "ce_trainer_hard = Trainer(model=ce_model, args=ce_args_hard, train_dataset=ft_train_ds)\n",
    "t0 = time.time()\n",
    "ce_trainer_hard.train()\n",
    "print(\"Hard-negative fine-tune done in %.1fs\" % (time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee15aa8c",
   "metadata": {},
   "source": [
    "## 8) Re-evaluate after hard-negative fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8e20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_top1group = evaluate_topk(val_df, top_n_groups=1, top_k_labels=TOP_K_LABELS)\n",
    "hard_topNgroups = evaluate_topk(val_df, top_n_groups=TOP_N_GROUPS, top_k_labels=TOP_K_LABELS)\n",
    "\n",
    "print(\"After hard-neg CE + top-1 group:\", hard_top1group)\n",
    "print(f\"After hard-neg CE + top-{TOP_N_GROUPS} groups:\", hard_topNgroups)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cdc3f",
   "metadata": {},
   "source": [
    "## 9) Summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b708dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame([\n",
    "    {\"variant\": \"baseline_CE_top1group\", **baseline_top1group},\n",
    "    {\"variant\": f\"baseline_CE_top{TOP_N_GROUPS}groups\", **baseline_topNgroups},\n",
    "    {\"variant\": \"hardneg_CE_top1group\", **hard_top1group},\n",
    "    {\"variant\": f\"hardneg_CE_top{TOP_N_GROUPS}groups\", **hard_topNgroups},\n",
    "])\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc8f9ed",
   "metadata": {},
   "source": [
    "## 10) Save artifacts\n",
    "\n",
    "This saves:\n",
    "- group model (calibrated)\n",
    "- cross-encoder model + tokenizer\n",
    "- group_to_labels mapping\n",
    "\n",
    "Use the final fine-tuned model for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4cd785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "OUT_DIR = Path(\"demand_ce_improved_artifacts\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(group_cal, OUT_DIR / \"group_model_calibrated.joblib\")\n",
    "ce_model.save_pretrained(OUT_DIR / \"cross_encoder\")\n",
    "ce_tokenizer.save_pretrained(OUT_DIR / \"cross_encoder\")\n",
    "\n",
    "mapping = {g: [{\"demand_id\": did, \"description\": desc} for did, desc in pairs] for g, pairs in group_to_labels.items()}\n",
    "(OUT_DIR / \"group_to_labels.json\").write_text(json.dumps(mapping, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Saved to:\", OUT_DIR.resolve())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
